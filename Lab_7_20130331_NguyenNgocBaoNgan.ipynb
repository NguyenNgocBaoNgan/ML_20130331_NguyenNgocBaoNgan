{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenNgocBaoNgan/ML_20130331_NguyenNgocBaoNgan/blob/main/Lab_7_20130331_NguyenNgocBaoNgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab deals with **cross validation** for some classification algorithms and **clustering methods**. \n",
        "\n",
        "*   **Deadline: 23:59, 10/4/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "u6X8PIuL0fxr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# CROSS VALIDATION\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import mode"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  1.1. Apply **SVM** algorithm with cross validation\n"
      ],
      "metadata": {
        "id": "x_dG9SA5OhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "data = datasets.load_iris()\n",
        "X = data['data']\n",
        "y = data['target']\n",
        "\n",
        "Xtrain,Xtest, ytrain,ytest = train_test_split(X, y,test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "62jExOZ952fF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='sigmoid',random_state=0) \n",
        "scores = cross_validate(clf,X,y,scoring='accuracy',cv=10)\n",
        "print(sorted(scores.keys()))\n",
        "print(np.mean(scores['test_score']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsOsYHbL1A20",
        "outputId": "b4ec42ae-bf01-452c-f58d-6d9ad79aac2c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fit_time', 'score_time', 'test_score']\n",
            "0.06666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.2 Apply **feature selection** to the dataset and then use **RandomForest** algorithm with cross validation "
      ],
      "metadata": {
        "id": "2g--8cng53sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape  #in so mau du lieu, tong so thuoc tinh\n",
        "X_new = SelectKBest(chi2, k=2).fit_transform(X,y)\n",
        "X_new.shape #sau khi scale\n",
        "\n",
        "#Create a Random Forest Classifier\n",
        "clf_rf=RandomForestClassifier(n_estimators=100)\n",
        "#Train the model using the training sets\n",
        "scores_acc = cross_validate(clf_rf,X_new,y,scoring='accuracy',cv=10)\n",
        "# scores_pre = cross_validate(clf_rf,X,y,scoring='precision_macro',cv=10)\n",
        "# scores_recall = cross_validate(clf_rf,X,y,scoring='recall_macro',cv=10)\n",
        "# scores_f1 = cross_validate(clf_rf,X,y,scoring='f1_macro',cv=10)\n",
        "\n",
        "print(sorted(scores_acc.keys()))\n",
        "print(np.mean(scores_acc['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JL4s7kW4e0E",
        "outputId": "0460cfa2-8eff-4723-9e94-4e38cb1202a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fit_time', 'score_time', 'test_score']\n",
            "0.9666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. With mnist dataset: \n",
        "*   2.1. Apply **K-Means** algorithm using k=10, "
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "mnist = datasets.load_digits()\n",
        "X = mnist['data']\n",
        "y = mnist['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters = 10, random_state = 0)\n",
        "kmeans.fit(mnist.data)\n",
        "clusters = kmeans.predict(mnist.data)\n",
        "kmeans.cluster_centers_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwjLlU6m9BAj",
        "outputId": "34f00405-990c-426e-b72b-29f720f78553"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.zeros_like(clusters)\n",
        "for i in range(10):\n",
        "    mask = (clusters == i)\n",
        "  #print(mask)\n",
        "    labels[mask] = mode(mnist.target[mask])[0]\n",
        "  #print(labels[mask])\n",
        "print(\"accuracy:\",accuracy_score(mnist.target, labels))\n",
        "print(\"precision:\",precision_score(mnist.target, labels, average='macro'))\n",
        "print(\"f1:\",f1_score(mnist.target, labels, average='macro'))\n",
        "print(\"recall:\",recall_score(mnist.target, labels, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zfYHD-O-Lj9",
        "outputId": "e6e6cce7-b532-474a-c798-2fd18430871b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7935447968836951\n",
            "precision: 0.8049510946090495\n",
            "f1: 0.7899801068577756\n",
            "recall: 0.7935735538874538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-308f25cde69e>:5: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  labels[mask] = mode(mnist.target[mask])[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.2. Compare the obtained result with with other classification algorithms such as **Randomforest**, **kNN**, and **Naïve Bayes** in terms of accuracy, precision, recall, f1 using cross validation. \n"
      ],
      "metadata": {
        "id": "pnoVB8J4vV36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "# Random Forest\n",
        "clf_rf = svm.SVC(kernel='sigmoid',random_state=0) \n",
        "scores_acc_rf = cross_validate(clf_rf,X,y,scoring='accuracy',cv=10)\n",
        "scores_pre_rf = cross_validate(clf_rf,X,y,scoring='precision_macro',cv=10)\n",
        "scores_recall_rf = cross_validate(clf_rf,X,y,scoring='recall_macro',cv=10)\n",
        "scores_f1_rf = cross_validate(clf_rf,X,y,scoring='f1_macro',cv=10)\n",
        "# print(sorted(scores.keys()))\n",
        "# print(np.mean(scores['test_score']))\n",
        "\n",
        "# kNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "scores_acc_knn = cross_validate(knn,X,y,scoring='accuracy',cv=10)\n",
        "scores_pre_knn = cross_validate(knn,X,y,scoring='precision_macro',cv=10)\n",
        "scores_recall_knn = cross_validate(knn,X,y,scoring='recall_macro',cv=10)\n",
        "scores_f1_knn = cross_validate(knn,X,y,scoring='f1_macro',cv=10)\n",
        "\n",
        "# Naïve Bayes\n",
        "nb = GaussianNB()\n",
        "scores_acc_nb = cross_validate(nb,X,y,scoring='accuracy',cv=10)\n",
        "scores_pre_nb = cross_validate(nb,X,y,scoring='precision_macro',cv=10)\n",
        "scores_recall_nb = cross_validate(nb,X,y,scoring='recall_macro',cv=10)\n",
        "scores_f1_nb = cross_validate(nb,X,y,scoring='f1_macro',cv=10)\n"
      ],
      "metadata": {
        "id": "-ZTSvsJdvYqI"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t= PrettyTable(['','acc','pre','recall','f1'])\n",
        "\n",
        "\n",
        "t.add_row(['Random Forest', np.mean(scores_acc_rf['test_score']),np.mean(scores_pre_rf['test_score']),np.mean(scores_recall_rf['test_score']),np.mean(scores_f1_rf['test_score'])])\n",
        "# t.add_row(['kNN', round(scores_acc_knn,2),round(scores_pre_knn,2),round(scores_recall_knn,2),round(scores_f1_knn,2)])\n",
        "# t.add_row(['Naive Bayes', round(scores_acc_nb,2),round(scores_pre_nb,2),round(scores_recall_nb,2),round(scores_f1_nb,2)])\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNwffwh2HJEe",
        "outputId": "980543b3-6200-4a43-c67d-b219c9e2bf7d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|               |        acc         |        pre         |       recall       |         f1         |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Random Forest | 0.8848013656114215 | 0.9011564046683042 | 0.8847832817337462 | 0.8857254060485733 |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.3. From the obtained results, **which approach is better** for this problem: Supervised learning or Unsupervised learning?"
      ],
      "metadata": {
        "id": "uyey-ndXvZlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "Qzh_D-rgvbv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4. Apply **AgglomerativeClustering** algorithm to mnist dataset using the number of clusters is 10"
      ],
      "metadata": {
        "id": "ol1U_T_NvcqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "For given dataset (shopping-data.csv) including 5 attributes: **CustomerID**, **Genre**, **Age**, **Annual Income**, and **Spending Score**.\n",
        "*   3.1. Using the **scipy library** to create the dendrograms for the given dataset (remember drop categorical attributes: **CustomerID**, **Genre**)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "YYY2dLtH3P8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.2. Apply K-Means to the preprocessed dataset with k belongs to [2,10]. Then compute SSE values and plot them to find the best value of k."
      ],
      "metadata": {
        "id": "eHlh_dWUyEMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "8vx3mfIidu4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.2. From the obtained dengrograms, choose an appropriate number of clusters and apply **AgglomerativeClustering** algorithm to the given dataset"
      ],
      "metadata": {
        "id": "RJpsTIiyv-1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "5ZE7A0Au1Pg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}